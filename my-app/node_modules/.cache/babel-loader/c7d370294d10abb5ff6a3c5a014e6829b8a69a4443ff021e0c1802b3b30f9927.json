{"ast":null,"code":"// // import React, { useEffect, useRef, useState } from \"react\";\n\n// // const LiveStream = () => {\n// //   const videoRef = useRef(null);\n// //   const canvasRef = useRef(null);\n// //   const [streaming, setStreaming] = useState(false);\n\n// //   useEffect(() => {\n// //     startCamera();\n// //     const interval = setInterval(() => {\n// //       if (streaming) {\n// //         captureAndSendFrame();\n// //       }\n// //     }, 1000); // Send frame every 1s\n\n// //     return () => {\n// //       stopCamera();\n// //       clearInterval(interval);\n// //     };\n// //   }, [streaming]);\n\n// //   const startCamera = async () => {\n// //     try {\n// //       const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n// //       videoRef.current.srcObject = stream;\n// //       setStreaming(true);\n// //     } catch (err) {\n// //       console.error(\"Camera error:\", err);\n// //     }\n// //   };\n\n// //   const stopCamera = () => {\n// //     if (videoRef.current && videoRef.current.srcObject) {\n// //       const tracks = videoRef.current.srcObject.getTracks();\n// //       tracks.forEach(track => track.stop());\n// //     }\n// //     setStreaming(false);\n// //   };\n\n// //   const captureAndSendFrame = async () => {\n// //     const video = videoRef.current;\n// //     const canvas = canvasRef.current;\n// //     if (!video || !canvas) return;\n\n// //     const context = canvas.getContext(\"2d\");\n// //     context.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n// //     const dataURL = canvas.toDataURL(\"image/jpeg\");\n\n// //     try {\n// //       const res = await fetch(\"http://localhost:5000/recognize\", {\n// //         method: \"POST\",\n// //         headers: { \"Content-Type\": \"application/json\" },\n// //         body: JSON.stringify({ image: dataURL }),\n// //       });\n\n// //       const data = await res.json();\n// //       drawBoxes(data.faces);\n// //     } catch (err) {\n// //       console.error(\"Recognition error:\", err);\n// //     }\n// //   };\n\n// //   const drawBoxes = (faces) => {\n// //     const canvas = canvasRef.current;\n// //     const ctx = canvas.getContext(\"2d\");\n\n// //     ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n// //     for (let face of faces) {\n// //       const { left, top, right, bottom, name } = face;\n// //       ctx.strokeStyle = \"green\";\n// //       ctx.lineWidth = 2;\n// //       ctx.strokeRect(left, top, right - left, bottom - top);\n\n// //       ctx.fillStyle = \"green\";\n// //       ctx.fillRect(left, top - 20, ctx.measureText(name).width + 10, 20);\n\n// //       ctx.fillStyle = \"white\";\n// //       ctx.font = \"16px Arial\";\n// //       ctx.fillText(name, left + 5, top - 5);\n// //     }\n// //   };\n\n// //   return (\n// //     <div>\n// //       <h2>Live Face Recognition</h2>\n// //       <div style={{ position: \"relative\", width: \"640px\", height: \"480px\" }}>\n// //         <video\n// //           ref={videoRef}\n// //           autoPlay\n// //           muted\n// //           width=\"640\"\n// //           height=\"480\"\n// //           style={{ position: \"absolute\", zIndex: 1 }}\n// //         />\n// //         <canvas\n// //           ref={canvasRef}\n// //           width=\"640\"\n// //           height=\"480\"\n// //           style={{ position: \"absolute\", zIndex: 2 }}\n// //         />\n// //       </div>\n// //     </div>\n// //   );\n// // };\n\n// // export default LiveStream;\n\n// import React, { useRef, useEffect } from \"react\";\n\n// function LiveStream() {\n//   const videoRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const faceMemoryRef = useRef({}); // Use ref to hold face data without re-rendering\n\n//   const canvasWidth = 640;\n//   const canvasHeight = 480;\n\n//   useEffect(() => {\n//     let intervalId;\n\n//     async function startCamera() {\n//       try {\n//         const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n//         videoRef.current.srcObject = stream;\n//         await videoRef.current.play();\n\n//         intervalId = setInterval(async () => {\n//           if (!videoRef.current || !canvasRef.current) return;\n\n//           const video = videoRef.current;\n//           const canvas = canvasRef.current;\n//           const ctx = canvas.getContext(\"2d\");\n\n//           // Draw current frame on canvas\n//           ctx.clearRect(0, 0, canvasWidth, canvasHeight);\n//           ctx.drawImage(video, 0, 0, canvasWidth, canvasHeight);\n\n//           // Get base64 image from canvas\n//           const dataUrl = canvas.toDataURL(\"image/jpeg\");\n\n//           try {\n//             const response = await fetch(\"http://localhost:5000/recognize\", {\n//               method: \"POST\",\n//               headers: { \"Content-Type\": \"application/json\" },\n//               body: JSON.stringify({ image: dataUrl }),\n//             });\n\n//             const result = await response.json();\n\n//             // Update faceMemoryRef with new detections\n//             const now = Date.now();\n//             const faceMemory = faceMemoryRef.current;\n\n//             result.faces.forEach(({ top, right, bottom, left, name }) => {\n//               const key = `${left}_${top}_${right}_${bottom}`;\n//               faceMemory[key] = { name, coords: { top, right, bottom, left }, timestamp: now };\n//             });\n\n//             // Remove stale faces older than 3 seconds\n//             Object.keys(faceMemory).forEach((key) => {\n//               if (now - faceMemory[key].timestamp > 3000) {\n//                 delete faceMemory[key];\n//               }\n//             });\n\n//             // Draw bounding boxes and names from stable faceMemory\n//             Object.values(faceMemory).forEach(({ name, coords }) => {\n//               const { top, right, bottom, left } = coords;\n//               ctx.strokeStyle = \"#00FF00\";\n//               ctx.lineWidth = 2;\n//               ctx.strokeRect(left, top, right - left, bottom - top);\n\n//               ctx.fillStyle = \"#00FF00\";\n//               ctx.font = \"18px Arial\";\n//               ctx.fillText(name, left, top > 20 ? top - 8 : bottom + 20);\n//             });\n//           } catch (error) {\n//             console.error(\"Error recognizing faces:\", error);\n//           }\n//         }, 800); // every 800ms\n\n//       } catch (err) {\n//         console.error(\"Camera error:\", err);\n//       }\n//     }\n\n//     startCamera();\n\n//     return () => {\n//       clearInterval(intervalId);\n//       if (videoRef.current && videoRef.current.srcObject) {\n//         videoRef.current.srcObject.getTracks().forEach(track => track.stop());\n//       }\n//     };\n//   }, []); // empty dependency array - run only once\n\n//   return (\n//     <div style={{ position: \"relative\", width: canvasWidth, height: canvasHeight }}>\n//       <video\n//         ref={videoRef}\n//         width={canvasWidth}\n//         height={canvasHeight}\n//         muted\n//         style={{ position: \"absolute\", top: 0, left: 0, zIndex: 1 }}\n//       />\n//       <canvas\n//         ref={canvasRef}\n//         width={canvasWidth}\n//         height={canvasHeight}\n//         style={{ position: \"absolute\", top: 0, left: 0, zIndex: 2 }}\n//       />\n//     </div>\n//   );\n// }\n\n// export default LiveStream;","map":{"version":3,"names":[],"sources":["G:/Coding/KATOMARAN-HACKATHON/my-app/src/components/assets/livestream/livestream.jsx"],"sourcesContent":["// // import React, { useEffect, useRef, useState } from \"react\";\r\n\r\n// // const LiveStream = () => {\r\n// //   const videoRef = useRef(null);\r\n// //   const canvasRef = useRef(null);\r\n// //   const [streaming, setStreaming] = useState(false);\r\n\r\n// //   useEffect(() => {\r\n// //     startCamera();\r\n// //     const interval = setInterval(() => {\r\n// //       if (streaming) {\r\n// //         captureAndSendFrame();\r\n// //       }\r\n// //     }, 1000); // Send frame every 1s\r\n\r\n// //     return () => {\r\n// //       stopCamera();\r\n// //       clearInterval(interval);\r\n// //     };\r\n// //   }, [streaming]);\r\n\r\n// //   const startCamera = async () => {\r\n// //     try {\r\n// //       const stream = await navigator.mediaDevices.getUserMedia({ video: true });\r\n// //       videoRef.current.srcObject = stream;\r\n// //       setStreaming(true);\r\n// //     } catch (err) {\r\n// //       console.error(\"Camera error:\", err);\r\n// //     }\r\n// //   };\r\n\r\n// //   const stopCamera = () => {\r\n// //     if (videoRef.current && videoRef.current.srcObject) {\r\n// //       const tracks = videoRef.current.srcObject.getTracks();\r\n// //       tracks.forEach(track => track.stop());\r\n// //     }\r\n// //     setStreaming(false);\r\n// //   };\r\n\r\n// //   const captureAndSendFrame = async () => {\r\n// //     const video = videoRef.current;\r\n// //     const canvas = canvasRef.current;\r\n// //     if (!video || !canvas) return;\r\n\r\n// //     const context = canvas.getContext(\"2d\");\r\n// //     context.drawImage(video, 0, 0, canvas.width, canvas.height);\r\n\r\n// //     const dataURL = canvas.toDataURL(\"image/jpeg\");\r\n\r\n// //     try {\r\n// //       const res = await fetch(\"http://localhost:5000/recognize\", {\r\n// //         method: \"POST\",\r\n// //         headers: { \"Content-Type\": \"application/json\" },\r\n// //         body: JSON.stringify({ image: dataURL }),\r\n// //       });\r\n\r\n// //       const data = await res.json();\r\n// //       drawBoxes(data.faces);\r\n// //     } catch (err) {\r\n// //       console.error(\"Recognition error:\", err);\r\n// //     }\r\n// //   };\r\n\r\n// //   const drawBoxes = (faces) => {\r\n// //     const canvas = canvasRef.current;\r\n// //     const ctx = canvas.getContext(\"2d\");\r\n\r\n// //     ctx.clearRect(0, 0, canvas.width, canvas.height);\r\n\r\n// //     for (let face of faces) {\r\n// //       const { left, top, right, bottom, name } = face;\r\n// //       ctx.strokeStyle = \"green\";\r\n// //       ctx.lineWidth = 2;\r\n// //       ctx.strokeRect(left, top, right - left, bottom - top);\r\n\r\n// //       ctx.fillStyle = \"green\";\r\n// //       ctx.fillRect(left, top - 20, ctx.measureText(name).width + 10, 20);\r\n\r\n// //       ctx.fillStyle = \"white\";\r\n// //       ctx.font = \"16px Arial\";\r\n// //       ctx.fillText(name, left + 5, top - 5);\r\n// //     }\r\n// //   };\r\n\r\n// //   return (\r\n// //     <div>\r\n// //       <h2>Live Face Recognition</h2>\r\n// //       <div style={{ position: \"relative\", width: \"640px\", height: \"480px\" }}>\r\n// //         <video\r\n// //           ref={videoRef}\r\n// //           autoPlay\r\n// //           muted\r\n// //           width=\"640\"\r\n// //           height=\"480\"\r\n// //           style={{ position: \"absolute\", zIndex: 1 }}\r\n// //         />\r\n// //         <canvas\r\n// //           ref={canvasRef}\r\n// //           width=\"640\"\r\n// //           height=\"480\"\r\n// //           style={{ position: \"absolute\", zIndex: 2 }}\r\n// //         />\r\n// //       </div>\r\n// //     </div>\r\n// //   );\r\n// // };\r\n\r\n// // export default LiveStream;\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// import React, { useRef, useEffect } from \"react\";\r\n\r\n// function LiveStream() {\r\n//   const videoRef = useRef(null);\r\n//   const canvasRef = useRef(null);\r\n//   const faceMemoryRef = useRef({}); // Use ref to hold face data without re-rendering\r\n\r\n//   const canvasWidth = 640;\r\n//   const canvasHeight = 480;\r\n\r\n//   useEffect(() => {\r\n//     let intervalId;\r\n\r\n//     async function startCamera() {\r\n//       try {\r\n//         const stream = await navigator.mediaDevices.getUserMedia({ video: true });\r\n//         videoRef.current.srcObject = stream;\r\n//         await videoRef.current.play();\r\n\r\n//         intervalId = setInterval(async () => {\r\n//           if (!videoRef.current || !canvasRef.current) return;\r\n\r\n//           const video = videoRef.current;\r\n//           const canvas = canvasRef.current;\r\n//           const ctx = canvas.getContext(\"2d\");\r\n\r\n//           // Draw current frame on canvas\r\n//           ctx.clearRect(0, 0, canvasWidth, canvasHeight);\r\n//           ctx.drawImage(video, 0, 0, canvasWidth, canvasHeight);\r\n\r\n//           // Get base64 image from canvas\r\n//           const dataUrl = canvas.toDataURL(\"image/jpeg\");\r\n\r\n//           try {\r\n//             const response = await fetch(\"http://localhost:5000/recognize\", {\r\n//               method: \"POST\",\r\n//               headers: { \"Content-Type\": \"application/json\" },\r\n//               body: JSON.stringify({ image: dataUrl }),\r\n//             });\r\n\r\n//             const result = await response.json();\r\n\r\n//             // Update faceMemoryRef with new detections\r\n//             const now = Date.now();\r\n//             const faceMemory = faceMemoryRef.current;\r\n\r\n//             result.faces.forEach(({ top, right, bottom, left, name }) => {\r\n//               const key = `${left}_${top}_${right}_${bottom}`;\r\n//               faceMemory[key] = { name, coords: { top, right, bottom, left }, timestamp: now };\r\n//             });\r\n\r\n//             // Remove stale faces older than 3 seconds\r\n//             Object.keys(faceMemory).forEach((key) => {\r\n//               if (now - faceMemory[key].timestamp > 3000) {\r\n//                 delete faceMemory[key];\r\n//               }\r\n//             });\r\n\r\n//             // Draw bounding boxes and names from stable faceMemory\r\n//             Object.values(faceMemory).forEach(({ name, coords }) => {\r\n//               const { top, right, bottom, left } = coords;\r\n//               ctx.strokeStyle = \"#00FF00\";\r\n//               ctx.lineWidth = 2;\r\n//               ctx.strokeRect(left, top, right - left, bottom - top);\r\n\r\n//               ctx.fillStyle = \"#00FF00\";\r\n//               ctx.font = \"18px Arial\";\r\n//               ctx.fillText(name, left, top > 20 ? top - 8 : bottom + 20);\r\n//             });\r\n//           } catch (error) {\r\n//             console.error(\"Error recognizing faces:\", error);\r\n//           }\r\n//         }, 800); // every 800ms\r\n\r\n//       } catch (err) {\r\n//         console.error(\"Camera error:\", err);\r\n//       }\r\n//     }\r\n\r\n//     startCamera();\r\n\r\n//     return () => {\r\n//       clearInterval(intervalId);\r\n//       if (videoRef.current && videoRef.current.srcObject) {\r\n//         videoRef.current.srcObject.getTracks().forEach(track => track.stop());\r\n//       }\r\n//     };\r\n//   }, []); // empty dependency array - run only once\r\n\r\n//   return (\r\n//     <div style={{ position: \"relative\", width: canvasWidth, height: canvasHeight }}>\r\n//       <video\r\n//         ref={videoRef}\r\n//         width={canvasWidth}\r\n//         height={canvasHeight}\r\n//         muted\r\n//         style={{ position: \"absolute\", top: 0, left: 0, zIndex: 1 }}\r\n//       />\r\n//       <canvas\r\n//         ref={canvasRef}\r\n//         width={canvasWidth}\r\n//         height={canvasHeight}\r\n//         style={{ position: \"absolute\", top: 0, left: 0, zIndex: 2 }}\r\n//       />\r\n//     </div>\r\n//   );\r\n// }\r\n\r\n// export default LiveStream;\r\n"],"mappings":"AAAA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAqBA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}